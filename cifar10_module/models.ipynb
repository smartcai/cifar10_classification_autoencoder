{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"models.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7FbFtlAySmOQ","colab_type":"code","colab":{}},"source":["import gc\n","import json\n","import random\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import seaborn as sn\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import confusion_matrix, classification_report\n","from keras.utils import np_utils\n","from keras.models import Model, load_model\n","from keras.layers import Input, Conv2D, MaxPooling2D, GlobalMaxPooling2D, Dense, UpSampling2D, BatchNormalization, Dropout, GaussianNoise\n","from keras.regularizers import l1,l2\n","from keras.optimizers import SGD, Adam, RMSprop\n","from keras.callbacks import EarlyStopping\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-gQ8I4Okft_8","colab_type":"code","colab":{}},"source":["def set_random_seeds(seed=42):\n","    '''Sets seed in python random number generator, numpy and tensorflow.\n","    \n","\n","    Parameters:\n","    \n","    seed(int): seed number \n","\n","    '''\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.compat.v1.set_random_seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cTzGm1WMIOkf","colab_type":"code","colab":{}},"source":["def load_saved_model(filename):\n","    return load_model('models/'+filename+'.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KredgJuka0Pj","colab_type":"code","colab":{}},"source":["def load_config(filepath):\n","    '''Returns a dictionary with a model configuration loaded from working\n","    directory.\n","    \n","\n","    Parameters: \n","    \n","    filepath(string): path to the configuration dictionary\n","\n","    Returns:\n","\n","    config(dict): dictionary with configuration\n","\n","    '''\n","    with open(filepath, 'r') as fp:\n","        config= json.load(fp)\n","    return config "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v5GTzW00bCBd","colab_type":"code","colab":{}},"source":["def save_config(config, filepath):\n","    '''Saves a dictionary with a model configuration in the working\n","    directory\n","    \n","\n","    Parameters:\n","    \n","    config(dict): dictionary with model configuration \n","\n","    '''    \n","    with open(filepath,'w') as fp:\n","        json.dump(config,fp)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eteTZ-FiF_J_","colab_type":"code","colab":{}},"source":["def plot_model_metrics(model_history, filename, loss=True, acc=True):\n","    ''' Plots and saves (in directory 'plots/') training and validation loss \n","    and accuracy\n","\n","    Parameters:\n","\n","    model_history(keras History): keras History object with records of training and \n","    validation loss and accuracy\n","\n","    filename(string): name to be given to loss and accuracy plot files\n","\n","    loss(boolean): whether to plot and save loss \n","\n","    acc(boolean): whether to plot and save accuracy\n","\n","    '''\n","    if loss:\n","        #plot loss\n","        fig1= plt.figure(1)\n","        plt.plot(model_history.history['loss'])\n","        plt.plot(model_history.history['val_loss'])\n","        plt.title('Model Loss')\n","        plt.ylabel('loss')\n","        annotation1 = 'Train loss: ' + str(round(model_history.history['loss'][len(model_history.history['loss'])-1],4))\n","        annotation2 = 'Val loss: ' + str(round(model_history.history['val_loss'][len(model_history.history['val_loss'])-1],4))\n","        annotation = annotation1 + ', ' + annotation2\n","        plt.xlabel('epoch \\n' + annotation)\n","        plt.legend(['train','validation'],loc='upper right')\n","        filepath = 'plots/' + filename + '_loss.png'\n","        plt.savefig(filepath, dpi=300,  bbox_inches = \"tight\")\n","\n","    if acc:\n","        #plot accuracy\n","        fig2= plt.figure(2)\n","        plt.plot(model_history.history['acc'])\n","        plt.plot(model_history.history['val_acc'])\n","        plt.title('Model Accuracy')\n","        plt.ylabel('accuracy')\n","        annotation1 = 'Train accuracy: ' + str(round(model_history.history['acc'][len(model_history.history['acc'])-1],4))\n","        annotation2 = 'Val accuracy: ' + str(round(model_history.history['val_acc'][len(model_history.history['val_acc'])-1],4))\n","        annotation = annotation1 + ', ' + annotation2\n","        plt.xlabel('epoch \\n' + annotation)\n","        plt.legend(['train','validation'],loc='upper right')\n","        filepath = 'plots/'+ filename + '_accuracy.png'\n","        plt.savefig(filepath,dpi=300, bbox_inches = \"tight\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2T8hNqYO1Xpb","colab":{}},"source":["def plot_confusion_matrix(cm, classes, normalize=True, figsize=(9,5)):\n","    ''' Plots confusion matrix\n","\n","    Parameters:\n","\n","    cm (confusion matrix array): confusion matrix array\n","\n","    classes(list): list containing unique class names used in the classification\n","\n","    normalize(boolean): whether to normalize confusion matrix values\n","\n","    figsize(tuple): \n","\n","    '''\n","    \n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        title='Normalized confusion matrix'\n","    else:\n","        title='Confusion matrix'\n","\n","    fmt= '.2f' if normalize else 'd'\n","    df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n","    fig = plt.figure(figsize=figsize)\n","    heatmap = sn.heatmap(df_cm, annot=True, fmt=fmt, cmap='Greys')\n","    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), \n","                                 rotation=0, \n","                                 ha='right')\n","    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), \n","                                 rotation=45, \n","                                 ha='right')\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.title(title)\n","    plt.tight_layout()\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"90ouV6Ye0R7B","colab_type":"code","colab":{}},"source":["def assert_kernel_regularizer(config):\n","    ''' Returns a regularizer object or None based on config\n","\n","    \n","    Parameters:\n","\n","    config(dict): dictionary with model configuration\n","\n","    \n","    Returns:\n","\n","    l1, l2, None(keras regularizer, None): depending on config, returns keras \n","    regularizers l1 or l2, or None\n","\n","    '''\n","    if config['kernel_regularizer']:\n","        if config['kernel_regularizer_type']=='l1':\n","            return l1(config['kernel_regularizer_value'])\n","        elif (config['kernel_regularizer_type']=='l2'):\n","            return l2(config['kernel_regularizer_value'])\n","        else:\n","            return l2()\n","    else:\n","        return None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_6jnolGwsRYl","colab_type":"code","colab":{}},"source":["def assert_activity_regularizer(config):\n","    ''' Returns a regularizer object or None based on config\n","    \n","    \n","    Parameters:\n","\n","    config(dict): dictionary with model configuration\n","\n","    \n","    Returns:\n","\n","    l1, l2, None(keras regularizer, None): depending on config, returns keras \n","    regularizers l1, l2, or None\n","\n","    '''\n","    if config['activity_regularizer']:\n","        if config['activity_regularizer_type']=='l1':\n","            return l1(config['activity_regularizer_value'])\n","        elif config['activity_regularizer_type']=='l2':\n","            return l2(config['activity_regularizer_value'])\n","        else:\n","            return None\n","    else:\n","        return None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AhlyZfJA6YKh","colab_type":"code","colab":{}},"source":["def assert_optimizer(config):\n","    ''' Returns an optimizer object based on config.\n","\n","    \n","    Parameters:\n","\n","    config(dict): dictionary with model configuration\n","\n","    \n","    Returns:\n","\n","    depending on config, returns keras optimizers Adam, SGD, RMSprop objects or None\n","\n","    '''\n","    if config['optimizer']=='adam':\n","        return Adam(lr=config['lr'])\n","    elif config['optimizer']=='sgd':\n","        return SGD(lr=config['lr'],momentum=True)\n","    elif config['optimizer']=='rmsprop':\n","        return RMSprop(lr=config['lr'])\n","    else:\n","        return SGD"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-73lT5zqZfVR","colab":{}},"source":["def get_class_weights(y,config):\n","    ''' Returns a dictionary of class weights.\n","\n","    \n","    Parameters:\n","\n","    y(numpy_array): one-hot encoded numpy array with classification values\n","\n","    config(dict): dictionary with model configuration\n","    \n","\n","    Returns:\n","\n","    depenfingon config, returns a dictionary with class weights or None\n","\n","    '''\n","    if config['class_weights']:\n","        y_labels= np.argmax(y,axis=1)\n","        class_labels =np.unique(y_labels)\n","        class_weights =compute_class_weight('balanced',class_labels,y_labels)\n","        print('Class weights:')\n","        print(dict_weights)\n","        dict_weights= dict(enumerate(class_weights))\n","        return dict_weights\n","    else:\n","        return None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VQd5CY-AfR9z","colab_type":"code","colab":{}},"source":["def  early_stopping(config):\n","    ''' Returns a encoder layer\n","\n","    \n","    Parameters:\n","\n","    config(dict): dictionary with model configuration\n","\n","    \n","    Returns:\n","\n","    depending on config, returns EarlySopping object or None\n","\n","    '''\n","    if config['early_stopping']:\n","        return EarlyStopping(monitor= 'val_loss',\n","                             min_delta= config['early_stopping_delta'],\n","                             patience= config['early_stopping_patience'],\n","                             restore_best_weights=True)\n","    else:\n","        return None "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eLUsgKFk2QwI","colab":{}},"source":["def encoder_conv_blocks(num_filters, en, config):\n","    ''' Returns a tensor  corresponing to the convolution block of an encoder \n","\n","    \n","    Parameters:\n","\n","    num_filtes(int): number of filters for the convolution block\n","\n","    en(tensor): tensor corresponding to previous block\n","\n","    config(config): dictionary with  model configuration\n","\n","    \n","    Returns:\n","\n","    en(tensor): tensor correspondind to a convolution block\n","\n","    '''\n","    kernel_regularizer = assert_kernel_regularizer(config)\n","    activity_regularizer = assert_activity_regularizer(config)\n","\n","    for i in range(0,config['layers_per_block']):\n","        en= Conv2D(num_filters,\n","                 (3,3), \n","                 padding='same', \n","                 strides=(1,1),\n","                 activation='relu', \n","                 kernel_initializer='glorot_uniform', \n","                 kernel_regularizer= kernel_regularizer,\n","                 activity_regularizer= activity_regularizer)(en)\n","        if config['batch_norm']:\n","            en= BatchNormalization()(en)\n","    en= MaxPooling2D((2,2))(en)\n","    if config['dropout']:\n","        en=Dropout(config['dropout_value'])(en)\n","    return en"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4xLRo9W6JsZd","colab_type":"code","colab":{}},"source":["def decoder_conv_blocks(num_filters, de, config):\n","    ''' Returns a tensor  corresponing to the convolution block of a decoder\n","\n","    \n","    Parameters:\n","\n","    num_filtes(int): number of filters for the convolution block\n","\n","    de(tensor): tensor corresponding to previous block\n","\n","    (config): dictionary with  model configuration\n","\n","    \n","    Returns:\n","\n","    en(tensor): tensor correspondind to a convolution block\n","\n","    '''\n","    for i in range(0,config['layers_per_block']):\n","        de= Conv2D(num_filters,\n","                  (3,3), \n","                  padding='same', \n","                  activation='relu',\n","                  strides=(1,1))(de)\n","        if config['batch_norm']:\n","            de= BatchNormalization()(de)\n","    de= UpSampling2D((2,2))(de)\n","    return de"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cu0nnpoHN8YW","colab_type":"code","colab":{}},"source":["def create_encoder(num_filters, en, config):\n","    ''' Returns a tensor  corresponing to an encoder (at each new conv block the \n","    bumber of filters is multiplied by 2)\n","\n","    Parameters:\n","\n","    num_filtes(int): number of filters to start the encoder with\n","\n","    en(tensor): tensor corresponding to previous block\n","\n","    (config): dictionary with  model configuration\n","\n","    \n","    Returns:\n","\n","    en(tensor), num_filters(int): tensor corresponding to an encoder and number of \n","    filters of its last convolution block \n","\n","    '''\n","    for i in range(0,config['conv_blocks']):\n","        if i==0:\n","            en= encoder_conv_blocks(num_filters, en, config)\n","        else:\n","            num_filters *= 2\n","            en= encoder_conv_blocks(num_filters, en, config)\n","    return en, num_filters"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JP-vHmIFPNnf","colab_type":"code","colab":{}},"source":["def create_decoder(num_filters, de, config):\n","    ''' Returns a tensor  corresponing to a decoder\n","\n","    \n","    Parameters:\n","\n","    num_filtes(int): number of filters to start the decoder with\n","\n","    de(tensor): tensor corresponding to previous block\n","\n","    (config): dictionary with  model configuration\n","\n","    \n","    Returns:\n","\n","    de(tensor), num_filters(int): tensor corresponding to a decoder and number of \n","    filters of its last convolution block \n","\n","    '''\n","    for i in range(0,config['conv_blocks']):\n","        if i==0:\n","            de= decoder_conv_blocks(num_filters, de, config)\n","        else:\n","            num_filters //= 2\n","            de= decoder_conv_blocks(num_filters, de, config)\n","    return de, num_filters"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"y0ytbI_4rhti","colab":{}},"source":["def create_autoencoder(config):\n","    ''' Returns an autoencoder model based on config\n","\n","    \n","    Parameters\n","\n","    config(dict): dictionary with  model configuration\n","\n","    \n","    Returns:\n","\n","    autoencoder(keras Model): autoencoder Model\n","\n","    '''\n","\n","    num_filters= config['init_num_filters']\n","    optimizer = assert_optimizer(config)\n","    img_input= Input(shape=config['image_shape'])\n","\n","    en=img_input\n","    if config['gaussian_noise']:\n","        en=GaussianNoise(config['gaussian_noise_stddev'])(en)\n","\n","    #Encoder  \n","    encoded, num_filters = create_encoder(num_filters, en, config)\n","    encoder= Model(img_input,encoded,name='encoder')\n","    encoder.summary()\n","\n","    #Decoder\n","    encoded_input= Input(shape=encoder.output_shape[1:])\n","    de,_= create_decoder(num_filters, encoded_input,config)\n","    decoded= Conv2D(3,\n","                    (3,3), \n","                    padding='same', \n","                    activation='sigmoid',\n","                    kernel_initializer='glorot_uniform')(de)\n","\n","    decoder= Model(encoded_input,decoded, name='decoder')\n","    decoder.summary()\n","\n","    autoencoder= Model(img_input,decoder(encoder(img_input)))\n","    autoencoder.compile(optimizer, \n","                    loss= config['loss'])\n","    autoencoder.summary()\n","\n","    return autoencoder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ym1cGA-9qzyc","colab_type":"code","colab":{}},"source":["def train_autoencoder(x_train, x_val, config, autoencoder_filename,encoder_filename):\n","    ''' Returns a trained autoencoder, saves trained autoencoder model, and \n","    plots training and validation metrics\n","\n","    \n","    Parameters\n","\n","    x_train(numpy array): numpy array with the training set\n","\n","    x_val(numpy array): numpy array with the validation set\n","\n","    config(dict): dictionary with  model configuration\n","\n","    \n","    Returns:\n","\n","    autoencoder(keras Model): autoencoder Model\n","\n","    '''\n","\n","    if config['callbacks']:\n","        callbacks=[early_stopping(config)]\n","    else:\n","        callbacks=None\n","\n","    autoencoder = create_autoencoder(config)\n","    autoencoder.summary()\n","    history= autoencoder.fit(x_train,\n","                            x_train,\n","                            batch_size= config['batch_size'],\n","                            epochs=config['epochs'],\n","                            callbacks=callbacks,\n","                            validation_data=(x_val,x_val))\n","    plot_model_metrics(history,autoencoder_filename,loss=True, acc=False)\n","    autoencoder.save('models/'+ autoencoder_filename + '.h5')\n","    autoencoder.get_layer(name='encoder').save('models/'+ encoder_filename + '.h5')\n","    return autoencoder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PXdGgRDMyRVJ","colab":{}},"source":["def create_classifier(autoencoder_config, classifier_config, \n","                      encoder_filename, classifier_filename):\n","    ''' Returns a cassifier model based on autoencoder_config and \n","    classifier_config\n","\n","\n","    Parameters:\n","\n","    autencoder_config(dict): dictionary with autoencoder model configuration\n","\n","    classifier_config(dict): dictionary with classifier model configuration\n","\n","    encoder_filename(string): filename without extension of the encoder\n","    to be loaded from models directory\n","    \n","    classifier_filename(string): filename without extension of the classifier\n","    to be loaded in models directory\n","\n","    Returns:\n","\n","    classifier(keras Model): classifier model with convolution layers corresponding\n","    to encoder frozen and weights loaded from the encoder component of the autoencoder\n","\n","    '''\n","\n","    num_filters= autoencoder_config['init_num_filters']\n","    optimizer = assert_optimizer(classifier_config)\n","    img_input= Input(shape=autoencoder_config['image_shape'])\n","\n","    # Encoder\n","    en, num_filters = create_encoder(num_filters, img_input, autoencoder_config)\n","\n","    # Classifier\n","    c= en\n","    if classifier_config['global_pooling']=='max':\n","        c= GlobalMaxPooling2D()(c)\n","    else:\n","        c= GobalAveragePooling2D()(c)\n","\n","    if (num_filters //2) > 16:\n","        c= Dense(num_filters //2, \n","                 kernel_initializer='glorot_uniform',\n","                 activation='relu')(c)\n","    output= Dense(10, \n","             activation='softmax',\n","             kernel_initializer='glorot_uniform')(c)\n","    classifier = Model(img_input, output)\n","    encoder= load_model('models/'+ encoder_filename +'.h5')\n","\n","    if autoencoder_config['gaussian_noise']:\n","        initial_layer=2\n","        subtracted_layers=1\n","    else: \n","        initial_layer=1\n","        subtracted_layers=0\n","    \n","    num_layers= len(encoder.layers)\n","\n","    print('Number of layers for weight transfer: ', num_layers-subtracted_layers-1)\n","    \n","    # load weights into encoder layers\n","    for l1,l2 in zip(classifier.layers[1:num_layers],\n","                     encoder.layers[initial_layer:num_layers-subtracted_layers]):\n","        l1.set_weights(l2.get_weights())\n","\n","    del encoder\n","    gc.collect()\n","\n","    for l in classifier.layers[:num_layers-subtracted_layers]:\n","        l.trainable=False\n","\n","    classifier.compile(optimizer, \n","                        loss= classifier_config['loss'], \n","                        metrics= ['accuracy'],\n","                        weighted_metrics=classifier_config['weighted_metrics'])\n","    return classifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KqKefof8qwKy","colab_type":"code","colab":{}},"source":["def train_classifier(x_train, x_val, y_train, y_val, \n","                     autoencoder_config, classifier_config, \n","                     encoder_filename, classifier_filename):\n","    \n","    ''' Returns a trained cassifier model based on autoencoder_config and \n","    classifier_config, saves trained classifier and plots training\n","    and validation metrics\n","\n","\n","    Parameters:\n","\n","    x_train(numpy array): numpy array with the training set\n","\n","    x_val(numpy array): numpy array with the validation set\n","\n","     y_train(numpy array): one-hot encoded numpy array with classification \n","    values for the training set\n","\n","    y_val(numpy array): one-hot encoded numpy array with classification \n","    values for the validation set\n","\n","    autencoder_config(dict): dictionary with autoencoder model configuration\n","\n","    classifier_config(dict): dictionary with classifier model configuration\n","\n","    autoencoder_filename(string): filename without extension of the autoencoder\n","    to be loaded from models directory\n","    \n","    classifier_filename(string): filename without extension of the classifier\n","    to be loaded in models directory\n","\n","    Returns:\n","\n","    classifier(keras Model): classifier model with convolution layers corresponding\n","    to encoder frozen and weights loaded from the encoder component of the autoencoder\n","\n","    '''\n","    \n","    classifier= create_classifier(autoencoder_config, \n","                                  classifier_config,\n","                                  encoder_filename, \n","                                  classifier_filename)\n","    classifier.summary()\n","\n","    if classifier_config['callbacks']:\n","        callbacks=[early_stopping(config)]\n","    else:\n","        callbacks=None\n","\n","    class_weight = get_class_weights(y_train, classifier_config)\n","\n","    if classifier_config['data_augmentation']:\n","        print('Using real-time data augmentation.')\n","        datagen = ImageDataGenerator(width_shift_range=0.1, \n","                                     height_shift_range=0.1, \n","                                     fill_mode='nearest',\n","                                     horizontal_flip=True)\n","        \n","        datagen.fit(x_train, seed=42)\n","        history=classifier.fit_generator(datagen.flow(x_train, \n","                                                      y_train, \n","                                                      batch_size=classifier_config['batch_size']),\n","                                         steps_per_epoch=x_train.shape[0] // classifier_config['batch_size'],\n","                                         epochs=classifier_config['epochs'],\n","                                         validation_data=(x_val, y_val),\n","                                         callbacks=callbacks,\n","                                         class_weight=class_weight)\n","        \n","        plot_model_metrics(history,classifier_filename,classifier_config)\n","        classifier.save('models/'+ classifier_filename + '.h5')\n","    else:\n","        history= classifier.fit(x_train,\n","                       y_train,\n","                       batch_size= classifier_config['batch_size'],\n","                       epochs=classifier_config['epochs'],\n","                       callbacks=callbacks,\n","                       validation_data=(x_val,y_val),\n","                       class_weight=class_weight)\n","        \n","        plot_model_metrics(history,classifier_filename,classifier_config)\n","        classifier.save('models/'+ classifier_filename + '.h5')\n","    \n","    return classifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2QrrhOeKKDb-","colab_type":"code","colab":{}},"source":["def tune_classifier(x_train, x_val, y_train, y_val, classifier_config, classifier_filename, tuned_classifier_filename):\n","    ''' Returns a tuned cassifier model after setting all layers to trainable,\n","    saves tuned classifier, and plots training and validation metrics\n","\n","\n","    Parameters:\n","\n","    x_train(numpy array): numpy array with the training set\n","\n","    x_val(numpy array): numpy array with the validation set\n","\n","     y_train(numpy array): one-hot encoded numpy array with classification \n","    values for the training set\n","\n","    y_val(numpy array): one-hot encoded numpy array with classification \n","    values for the validation set\n","\n","    autencoder_config(dict): dictionary with autoencoder model configuration\n","\n","    classifier_config(dict): dictionary with classifier model configuration\n","\n","    autoencoder_filename(string): filename without extension of the autoencoder\n","    to be loaded from models directory\n","    \n","    classifier_filename(string): filename without extension of the classifier\n","    to be loaded in models directory\n","\n","    Returns:\n","\n","    classifier(keras Model): classifier model with convolution layers corresponding\n","    to encoder frozen and weights loaded from the encoder component of the autoencoder\n","\n","    '''\n","    \n","    if classifier_config['callbacks']:\n","        callbacks=[early_stopping(config)]\n","    else:\n","        callbacks=None\n","    \n","    class_weight = get_class_weights(y_train, classifier_config)\n","\n","    #print(callbacks)\n","    #print(class_weight)\n","    #print(classifier_config['weighted_metrics'])\n","\n","    for l in classifier.layers:\n","        l.trainable=True\n","\n","    optimizer= assert_optimizer(classifier_config)\n","    classifier.compile(optimizer, \n","                        loss= classifier_config['loss'], \n","                        metrics= ['accuracy'],\n","                        weighted_metrics=classifier_config['weighted_metrics'])\n","    classifier.summary()\n","\n","    if classifier_config['data_augmentation']:\n","        print('Using real-time data augmentation.')\n","        datagen = ImageDataGenerator(width_shift_range=0.1, \n","                                     height_shift_range=0.1, \n","                                     fill_mode='nearest',\n","                                     horizontal_flip=True)\n","        \n","        datagen.fit(x_train, seed=42)\n","        history=classifier.fit_generator(datagen.flow(x_train, \n","                                                      y_train, \n","                                                      batch_size=classifier_config['batch_size']),\n","                                         steps_per_epoch=x_train.shape[0] // classifier_config['batch_size'],\n","                                         epochs=classifier_config['tune_ephocs'],\n","                                         validation_data=(x_val, y_val),\n","                                         callbacks=callbacks,\n","                                         class_weights=class_weights)\n","        \n","        plot_model_metrics(history,tuned_classifier_filename,classifier_config)\n","        classifier.save('models/'+ tuned_classifier_filename + '.h5')\n","    else:\n","        history= classifier.fit(x_train,\n","                       y_train,\n","                       batch_size= classifier_config['batch_size'],\n","                       epochs=classifier_config['epochs'],\n","                       callbacks=callbacks,\n","                       validation_data=(x_val,y_val),\n","                       class_weight=class_weight)\n","        \n","        plot_model_metrics(history,tuned_classifier_filename,classifier_config)\n","        classifier.save('models/'+ tuned_classifier_filename + '.h5')\n","    \n","    return classifier\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLQ_2AyfcRLC","colab_type":"code","colab":{}},"source":["def classifier_predict_evaluate( x, y, classifier, class_names):\n","    ''' Returns classifier prediction for x, plots confusion matrix, and prints\n","    classification report\n","\n","    \n","    Parameters:\n","\n","    x(numpy array):  numpy array with image samples\n","\n","    y(numpy array):  one-hot encoded numpy array with ground truth for the c\n","    classificaiton of images in x\n","\n","    classifier(Model): a keras mode for classification\n","\n","    class_names(list): list of unique classes in cifar10 \n","\n","    \n","    Returns:\n","\n","    y_pred(numpy array): one-hot encoded numpy array with the prediction for the\n","    classification of images in x\n","    '''\n","    y_pred = classifier.predict(x)\n","    cm= confusion_matrix(y.argmax(axis=1), y_pred.argmax(axis=1))\n","    plot_confusion_matrix(cm, class_names)\n","    print('')\n","    cr= classification_report(y.argmax(axis=1),\n","                              y_pred.argmax(axis=1), \n","                              target_names=class_names)\n","    print(cr)\n","    y_pred = np_utils.to_categorical(y_pred.argmax(axis=1))\n","    return y_pred"],"execution_count":0,"outputs":[]}]}