{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"modelling4.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"7FbFtlAySmOQ","colab":{}},"source":["import gc\n","import json\n","import random\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import seaborn as sn\n","import pandas as pd\n","import numpy as np\n","import keras.backend as K\n","\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import confusion_matrix, classification_report\n","from keras.utils import np_utils\n","from keras.models import Model, load_model\n","from keras.layers import Input, Conv2D, MaxPooling2D, GlobalMaxPooling2D, Dense, Flatten, UpSampling2D, BatchNormalization, Dropout, GaussianNoise, Flatten\n","from keras.regularizers import l1,l2\n","from keras.optimizers import SGD, Adam, RMSprop\n","from keras.callbacks import EarlyStopping\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-gQ8I4Okft_8","colab":{}},"source":["def set_random_seeds(seed=42):\n","    '''Sets seed in python random number generator, numpy and tensorflow\n","    \n","\n","    Parameters:\n","    \n","    seed(int): seed number \n","\n","    '''\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.compat.v1.set_random_seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cTzGm1WMIOkf","colab":{}},"source":["def load_saved_model(filename):\n","    '''Returns a saved model.\n","    \n","\n","    Parameters:\n","    \n","    filename(string): name of the saved model to load \n","\n","    '''\n","    return load_model('models/'+ filename +'.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pGZBGMiPFBB1","colab":{}},"source":["def load_history(filename):\n","    '''Returns an instance of History \n","\n","    Parameters: \n","    \n","    filename(string): name of the json file containing a model history\n","    without the extension\n","\n","    \n","    Returns:\n","\n","    config(dict): dictionary with configuration\n","\n","    '''\n","    history=None\n","    filepath= 'history/'+ filename +'.json'\n","    with open(filepath,'r') as fp:\n","        history= json.load(fp)\n","\n","    return history\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qwdF3MALSWWq","colab":{}},"source":["def save_history(history, filename):\n","    '''Saves a dictionary with a model configuration in the working\n","    directory as a json file\n","    \n","\n","    Parameters:\n","    \n","    config(dict): dictionary with model configuration\n","\n","    filepath(string): filepath where the configuration \n","    should be saved\n","\n","    '''\n","    filepath= 'history/' + filename + '.json'    \n","    with open(filepath,'w') as fp:\n","        json.dump(history,fp)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KredgJuka0Pj","colab":{}},"source":["def load_config(filepath):\n","    '''Returns a dictionary with a model configuration loaded from working\n","    directory.\n","    \n","\n","    Parameters: \n","    \n","    filepath(string): path to the configuration json file\n","\n","    \n","    Returns:\n","\n","    config(dict): dictionary with configuration\n","\n","    '''\n","    config= None\n","    with open(filepath, 'r') as fp:\n","        config= json.load(fp)\n","    return config "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"v5GTzW00bCBd","colab":{}},"source":["def save_config(config, filepath):\n","    '''Saves a dictionary with a model configuration in the working\n","    directory as a json file\n","    \n","\n","    Parameters:\n","    \n","    config(dict): dictionary with model configuration\n","\n","    filepath(string): filepath where the configuration \n","    should be saved\n","\n","    '''    \n","    with open(filepath,'w') as fp:\n","        json.dump(config,fp)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2T8hNqYO1Xpb","colab":{}},"source":["def plot_confusion_matrix(cm, classes, normalize=True, figsize=(9,5)):\n","    ''' Plots confusion matrix\n","\n","    Parameters:\n","\n","    cm (confusion matrix 2darray): confusion matrix array\n","\n","    classes(list): list containing unique class names used in the classification\n","\n","    normalize(boolean): whether to normalize confusion matrix \n","\n","    figsize(tuple): tuple with width and height of confusion matrix plot\n","\n","    '''\n","    \n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        title='Normalized confusion matrix'\n","    else:\n","        title='Confusion matrix'\n","\n","    fmt= '.2f' if normalize else 'd'\n","    df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n","    fig = plt.figure(figsize=figsize)\n","    heatmap = sn.heatmap(df_cm, annot=True, fmt=fmt, cmap='Greys')\n","    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), \n","                                 rotation=0, \n","                                 ha='right')\n","    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), \n","                                 rotation=45, \n","                                 ha='right')\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.title(title)\n","    plt.tight_layout()\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"90ouV6Ye0R7B","colab":{}},"source":["def assert_kernel_regularizer(config):\n","    ''' Returns a Regularizer object or None based on config\n","\n","    \n","    Parameters:\n","\n","    config(dict): dictionary with model configuration\n","\n","    \n","    Returns:\n","\n","    depending on config, returns keras Regularizer instance l1 or l2, or None\n","\n","    '''\n","    if config['kernel_regularizer']:\n","        if config['kernel_regularizer_type']=='l1':\n","            return l1(config['kernel_regularizer_value'])\n","        elif (config['kernel_regularizer_type']=='l2'):\n","            return l2(config['kernel_regularizer_value'])\n","        else:\n","            return l2()\n","    else:\n","        return None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_6jnolGwsRYl","colab":{}},"source":["def assert_activity_regularizer(config):\n","    ''' Returns a Regularizer instance or None based on config\n","    \n","    \n","    Parameters:\n","\n","    config(dict): dictionary with model configuration\n","\n","    \n","    Returns:\n","\n","    depending on config, returns keras Regularizer instance l1 or l2, or None\n","\n","    '''\n","    if config['activity_regularizer']:\n","        if config['activity_regularizer_type']=='l1':\n","            return l1(config['activity_regularizer_value'])\n","        elif config['activity_regularizer_type']=='l2':\n","            return l2(config['activity_regularizer_value'])\n","        else:\n","            return None\n","    else:\n","        return None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AhlyZfJA6YKh","colab":{}},"source":["def assert_optimizer(config):\n","    ''' Returns an optimizer object based on config.\n","\n","    \n","    Parameters:\n","\n","    config(dict): dictionary with model configuration\n","\n","    \n","    Returns:\n","\n","    depending on config, returns keras Optimizer instance Adam, SGD, or RMSprop\n","\n","    '''\n","    if config['optimizer']=='adam':\n","        return Adam(lr=config['lr'])\n","    elif config['optimizer']=='sgd':\n","        return SGD(lr=config['lr'],momentum=True)\n","    elif config['optimizer']=='rmsprop':\n","        return RMSprop(lr=config['lr'])\n","    else:\n","        return SGD"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-73lT5zqZfVR","colab":{}},"source":["def get_class_weights(y,config):\n","    ''' Returns a dictionary of class weights.\n","\n","    \n","    Parameters:\n","\n","    y(2d array): one-hot encoded ndarray with classification values\n","\n","    config(dict): dictionary with model configuration\n","    \n","\n","    Returns:\n","\n","    depending on config, returns a dictionary with class weights or None\n","\n","    '''\n","    if config['class_weights']:\n","        y_labels= np.argmax(y,axis=1)\n","        class_labels =np.unique(y_labels)\n","        class_weights =compute_class_weight('balanced',class_labels,y_labels)\n","        print('Class weights:')\n","        print(dict_weights)\n","        dict_weights= dict(enumerate(class_weights))\n","        return dict_weights\n","    else:\n","        return None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VQd5CY-AfR9z","colab":{}},"source":["def  early_stopping(config):\n","    ''' Returns a encoder layer\n","\n","    \n","    Parameters:\n","\n","    config(dict): dictionary with model configuration\n","\n","    \n","    Returns:\n","\n","    depending on config, returns an instance of EarlyStopping or None\n","\n","    '''\n","    if config['early_stopping']:\n","        return EarlyStopping(monitor= 'val_loss',\n","                             min_delta= config['early_stopping_delta'],\n","                             patience= config['early_stopping_patience'],\n","                             restore_best_weights=True)\n","    else:\n","        return None "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eLUsgKFk2QwI","colab":{}},"source":["def encoder_conv_blocks(num_filters, en, config):\n","    ''' Returns a tensor  corresponding to a convolution block of an encoder \n","\n","    \n","    Parameters:\n","\n","    num_filtes(int): number of filters for the convolution block\n","\n","    en(4d tensor): tensor corresponding to previous block\n","\n","    config(dict): dictionary with  model configuration\n","\n","    \n","    Returns:\n","\n","    en(4d tensor): tensor corresponding to a convolution block\n","\n","    '''\n","    kernel_regularizer = assert_kernel_regularizer(config)\n","    activity_regularizer = assert_activity_regularizer(config)\n","    regularization_control = config['init_num_filters']*(2*config['conv_blocks'])\n","\n","    for i in range(0,config['layers_per_block']):\n","        en= Conv2D(num_filters,\n","                 (3,3), \n","                 padding='same', \n","                 strides=(1,1),\n","                 activation='relu', \n","                 kernel_initializer='glorot_uniform', \n","                 kernel_regularizer= kernel_regularizer,\n","                 activity_regularizer= activity_regularizer)(en)\n","        if config['batch_norm']:\n","            en= BatchNormalization()(en) \n","        if config['gaussian_noise_hidden'] and num_filters < regularization_control:\n","            en= GaussianNoise(config['gaussian_noise_stddev'])(en)\n","    en= MaxPooling2D((2,2))(en)\n","    if config['dropout'] and num_filters < regularization_control:\n","        en=Dropout(config['dropout_value'])(en)\n","    return en"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4xLRo9W6JsZd","colab":{}},"source":["def decoder_conv_blocks(num_filters, de, config):\n","    ''' Returns a tensor  corresponding to the convolution block of a decoder\n","\n","    \n","    Parameters:\n","\n","    num_filters(int): number of filters for the convolution block\n","\n","    de(4d tensor): tensor corresponding to previous block\n","\n","    config(dict): dictionary with  model configuration\n","\n","    \n","    Returns:\n","\n","    en(4d tensor): tensor correspondind to a convolution block\n","\n","    '''\n","    for i in range(0,config['layers_per_block']):\n","        de= Conv2D(num_filters,\n","                  (3,3), \n","                  padding='same', \n","                  activation='relu',\n","                  strides=(1,1))(de)\n","        if config['batch_norm']:\n","            de= BatchNormalization()(de)\n","    de= UpSampling2D((2,2))(de)\n","    return de"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Cu0nnpoHN8YW","colab":{}},"source":["def create_encoder(num_filters, en, config):\n","    ''' Returns a tensor  corresponing to an encoder (at each new conv block the \n","    bumber of filters is multiplied by 2)\n","\n","    Parameters:\n","\n","    num_filtes(int): number of filters to start the encoder with\n","\n","    en(4d tensor): tensor corresponding to previous block\n","\n","    config(dict): dictionary with  model configuration\n","\n","    \n","    Returns:\n","\n","    en(4d tensor), num_filters(int): tensor corresponding to an encoder and number of \n","    filters of its last convolution block \n","\n","    '''\n","    for i in range(0,config['conv_blocks']):\n","        if i==0:\n","            en= encoder_conv_blocks(num_filters, en, config)\n","        else:\n","            num_filters *= 2\n","            en= encoder_conv_blocks(num_filters, en, config)\n","    return en, num_filters"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JP-vHmIFPNnf","colab":{}},"source":["def create_decoder(num_filters, de, config):\n","    ''' Returns a tensor  corresponing to a decoder\n","\n","    \n","    Parameters:\n","\n","    num_filters(int): number of filters to start the decoder with\n","\n","    de(4d tensor): tensor corresponding to previous block\n","\n","    config(dict): dictionary with  model configuration\n","\n","    \n","    Returns:\n","\n","    de(4d tensor), num_filters(int): tensor corresponding to a decoder and number of \n","    filters of its last convolution block \n","\n","    '''\n","    for i in range(0,config['conv_blocks']):\n","        if i==0:\n","            de= decoder_conv_blocks(num_filters, de, config)\n","        else:\n","            num_filters //= 2\n","            de= decoder_conv_blocks(num_filters, de, config)\n","    return de, num_filters"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"y0ytbI_4rhti","colab":{}},"source":["def create_autoencoder(config):\n","    ''' Returns an autoencoder model based on config\n","\n","    \n","    Parameters\n","\n","    config(dict): dictionary with  model configuration\n","\n","    \n","    Returns:\n","\n","    autoencoder(Model): Model instance of an autoencoder\n","\n","    '''\n","\n","    num_filters= config['init_num_filters']\n","    optimizer = assert_optimizer(config)\n","    img_input= Input(shape=config['image_shape'])\n","\n","    en=img_input\n","    if config['gaussian_noise_input']:\n","        en=GaussianNoise(config['gaussian_noise_stddev'])(en)\n","\n","    #Encoder  \n","    encoded, num_filters = create_encoder(num_filters, en, config)\n","    encoder= Model(img_input,encoded,name='encoder')\n","    encoder.summary()\n","\n","    #Decoder\n","    encoded_input= Input(shape=encoder.output_shape[1:])\n","    de,_= create_decoder(num_filters, encoded_input,config)\n","    decoded= Conv2D(3,\n","                    (3,3), \n","                    padding='same', \n","                    activation='sigmoid',\n","                    kernel_initializer='glorot_uniform')(de)\n","\n","    decoder= Model(encoded_input,decoded, name='decoder')\n","    decoder.summary()\n","\n","    autoencoder= Model(img_input,decoder(encoder(img_input)))\n","    autoencoder.compile(optimizer, \n","                    loss= config['loss'])\n","    autoencoder.summary()\n","\n","    return autoencoder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ym1cGA-9qzyc","colab":{}},"source":["def train_autoencoder(x_train, x_val, config, autoencoder_filename,encoder_filename):\n","    ''' Returns a trained autoencoder, saves trained autoencoder model, and \n","    plots training and validation metrics\n","\n","    \n","    Parameters\n","\n","    x_train(4d array): 4d array with the training set\n","\n","    x_val(4d array): 4d array array with the validation set\n","\n","    config(dict): dictionary with  model configuration\n","\n","    \n","    Returns:\n","\n","    autoencoder(Model): instance of model with trained autoencoder\n","\n","    '''\n","\n","    if config['callbacks']:\n","        callbacks=[early_stopping(config)]\n","    else:\n","        callbacks=None\n","\n","    autoencoder = create_autoencoder(config)\n","    autoencoder.summary()\n","    history= autoencoder.fit(x_train,\n","                            x_train,\n","                            batch_size= config['batch_size'],\n","                            epochs=config['epochs'],\n","                            callbacks=callbacks,\n","                            validation_data=(x_val,x_val))\n","    plot_model_metrics(history,autoencoder_filename,loss=True, acc=False)\n","    autoencoder.save('models/'+ autoencoder_filename + '.h5')\n","    autoencoder.get_layer(name='encoder').save('models/'+ encoder_filename + '.h5')\n","    return autoencoder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ECAQVvH--Aqw","colab":{}},"source":["def create_classifier(autoencoder_config, classifier_config, \n","                      encoder_filename, classifier_filename):\n","    ''' Returns a cassifier model based on autoencoder_config and \n","    classifier_config\n","\n","\n","    Parameters:\n","\n","    autencoder_config(dict): dictionary with autoencoder model configuration\n","\n","    classifier_config(dict): dictionary with classifier model configuration\n","\n","    encoder_filename(string): filename without extension of the encoder\n","    to be loaded from '.../models/' directory\n","    \n","    classifier_filename(string): filename without extension of the classifier\n","    to be saved in '.../models/' directory\n","\n","    Returns:\n","\n","    classifier(Model): classifier model with convolution layers corresponding\n","    to encoder, encoder layers frozen and weights loaded from the encoder \n","    component of the autoencoder\n","\n","    '''\n","\n","    num_filters= autoencoder_config['init_num_filters']\n","    shape_conv = autoencoder_config['image_shape']\n","    optimizer = assert_optimizer(classifier_config)\n","    img_input= Input(shape=autoencoder_config['image_shape'])\n","\n","    # Encoder\n","    en, num_filters = create_encoder(num_filters, img_input, autoencoder_config)\n","\n","    # Classifier\n","    c= Conv2D(num_filters,(3,3),\n","              padding='same',\n","              kernel_initializer='glorot_uniform')(en)\n","    if classifier_config['batch_norm']:\n","        c= BatchNormalization()(c)\n","    if classifier_config['dropout']:\n","        c= Dropout(classifier_config['dropout_value'])(c)\n","\n","    if classifier_config['global_pooling']=='max':\n","        c= GlobalMaxPooling2D()(c)\n","    \n","    if classifier_config['global_pooling']=='average':\n","        c= GobalAveragePooling2D()(c)\n","\n","    if classifier_config['global_pooling']=='flatten':\n","        c= Flatten()(c)\n","        c= Dense(num_filters, \n","                 kernel_initializer='glorot_uniform',\n","                 activation='relu')(c)\n","        if classifier_config['batch_norm']:\n","            c= BatchNormalization()(c)\n","                 \n","    if (num_filters //2) > 16 and classifier_config['dense']:\n","        c= Dense(num_filters //2, \n","                 kernel_initializer='glorot_uniform',\n","                 activation='relu')(c)\n","        c= BatchNormalization()(c)\n","\n","    output= Dense(10, \n","             activation='softmax',\n","             kernel_initializer='glorot_uniform')(c)\n","    classifier = Model(img_input, output)\n","    encoder= load_model('models/'+ encoder_filename +'.h5')\n","\n","    if autoencoder_config['gaussian_noise_input']:\n","        initial_layer=2\n","        subtracted_layers=1\n","    else: \n","        initial_layer=1\n","        subtracted_layers=0\n","    \n","    num_layers= len(encoder.layers)\n","    \n","    # load weights into encoder layers\n","    for l1,l2 in zip(classifier.layers[1:num_layers-subtracted_layers],encoder.layers[initial_layer:num_layers]):\n","        l1.set_weights(l2.get_weights())\n","\n","    del encoder\n","    gc.collect()\n","\n","    for l in classifier.layers[:num_layers-subtracted_layers]:\n","        l.trainable=False\n","\n","    classifier.compile(optimizer, \n","                        loss= classifier_config['loss'], \n","                        metrics= ['accuracy'],\n","                        weighted_metrics=classifier_config['weighted_metrics'])\n","    return classifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KqKefof8qwKy","colab":{}},"source":["def train_classifier(x_train, x_val, y_train, y_val, \n","                     autoencoder_config, classifier_config, \n","                     encoder_filename, classifier_filename):\n","    \n","    ''' Returns a trained cassifier model based on autoencoder_config and \n","    classifier_config, saves trained classifier and plots training\n","    and validation metrics\n","\n","\n","    Parameters:\n","\n","    x_train(4d array): 4d array with the training set\n","\n","    x_val(4d array): 4d array with the validation set\n","\n","    y_train(2d array): one-hot encoded 2d array with classification \n","    values for the training set\n","\n","    y_val(2d array): one-hot encoded numpy array with classification \n","    values for the validation set\n","\n","    autencoder_config(dict): dictionary with autoencoder model configuration\n","\n","    classifier_config(dict): dictionary with classifier model configuration\n","\n","    autoencoder_filename(string): filename without extension of the autoencoder\n","    to be loaded from '.../models/' directory\n","    \n","    classifier_filename(string): filename without extension of the classifier\n","    to be loaded in '.../models/' directory\n","\n","\n","    Returns:\n","\n","    classifier(Model): instance of Model with trained classifier\n","    '''\n","    \n","    classifier= create_classifier(autoencoder_config, \n","                                  classifier_config,\n","                                  encoder_filename, \n","                                  classifier_filename)\n","    classifier.summary()\n","\n","    if classifier_config['callbacks']:\n","        callbacks=[early_stopping(config)]\n","    else:\n","        callbacks=None\n","\n","    class_weight = get_class_weights(y_train, classifier_config)\n","\n","    if classifier_config['data_augmentation']:\n","        print('Using real-time data augmentation.')\n","        datagen = ImageDataGenerator(width_shift_range=0.1, \n","                                     height_shift_range=0.1, \n","                                     fill_mode='nearest',\n","                                     rotation_range=40,\n","                                     zoom_range=0.1,\n","                                     horizontal_flip=True)\n","        \n","        datagen.fit(x_train, seed=42)\n","        history=classifier.fit_generator(datagen.flow(x_train, \n","                                                      y_train, \n","                                                      batch_size=classifier_config['batch_size']),\n","                                         steps_per_epoch=x_train.shape[0] // classifier_config['batch_size'],\n","                                         epochs=classifier_config['epochs'],\n","                                         validation_data=(x_val, y_val),\n","                                         callbacks=callbacks,\n","                                         class_weight=class_weight)\n","        \n","        plot_model_metrics(history, classifier_filename, classifier_config)\n","        save_history(history.history, classifier_filename)\n","        classifier.save('models/'+ classifier_filename + '.h5')\n","    else:\n","        history= classifier.fit(x_train,\n","                       y_train,\n","                       batch_size= classifier_config['batch_size'],\n","                       epochs=classifier_config['epochs'],\n","                       callbacks=callbacks,\n","                       validation_data=(x_val,y_val),\n","                       class_weight=class_weight)\n","        \n","        plot_model_metrics(history,classifier_filename,classifier_config)\n","        save_history(history.history, classifier_filename)\n","        classifier.save('models/'+ classifier_filename + '.h5')\n","    \n","    return classifier"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iLQ_2AyfcRLC","colab":{}},"source":["def classifier_predict_evaluate( x, y, classifier, class_names):\n","    ''' Returns classifier prediction for x, plots confusion matrix, and prints\n","    classification report\n","\n","    \n","    Parameters:\n","\n","    x(4d array):  numpy array with image samples\n","\n","    y(2d array):  one-hot encoded 4d array with ground truth for the classificaiton \n","    of images in x\n","\n","    classifier(Model): instance of Model with classifier\n","\n","    class_names(list): list of unique classes in the dataset under study \n","\n","    \n","    Returns:\n","\n","    y_pred(numpy array): one-hot encoded numpy array with the prediction for the\n","    classification of images in x\n","    '''\n","    y_pred = classifier.predict(x)\n","    cm= confusion_matrix(y.argmax(axis=1), y_pred.argmax(axis=1))\n","    plot_confusion_matrix(cm, class_names)\n","    print('')\n","    cr= classification_report(y.argmax(axis=1),\n","                              y_pred.argmax(axis=1), \n","                              target_names=class_names)\n","    print(cr)\n","    y_pred = np_utils.to_categorical(y_pred.argmax(axis=1))\n","    return y_pred"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eteTZ-FiF_J_","colab":{}},"source":["def plot_model_metrics(model_history, filename, loss=True, acc=True):\n","    ''' Plots and saves (in directory 'plots/') training and validation loss \n","    and accuracy\n","\n","    Parameters:\n","\n","    model_history(keras History): keras History object with records of training and \n","    validation loss and accuracy\n","\n","    filename(string): name to be concatenated with loss and accuracy plot files \n","\n","    loss(boolean): whether to plot loss and save plot\n","\n","    acc(boolean): whether to plot accuracy and save the plot\n","\n","    '''\n","    if loss:\n","        #plot loss\n","        fig1= plt.figure(1)\n","        plt.plot(model_history.history['loss'])\n","        plt.plot(model_history.history['val_loss'])\n","        plt.title('Model Loss')\n","        plt.ylabel('loss')\n","        annotation1 = 'Train loss: ' + str(round(model_history.history['loss'][len(model_history.history['loss'])-1],4))\n","        annotation2 = 'Val loss: ' + str(round(model_history.history['val_loss'][len(model_history.history['val_loss'])-1],4))\n","        annotation = annotation1 + ', ' + annotation2\n","        plt.xlabel('epoch \\n' + annotation)\n","        plt.legend(['train','validation'],loc='upper right')\n","        filepath = 'plots/' + filename + '_loss.png'\n","        plt.savefig(filepath, dpi=300,  bbox_inches = \"tight\")\n","\n","    if acc:\n","        #plot accuracy\n","        fig2= plt.figure(2)\n","        plt.plot(model_history.history['acc'])\n","        plt.plot(model_history.history['val_acc'])\n","        plt.title('Model Accuracy')\n","        plt.ylabel('accuracy')\n","        annotation1 = 'Train accuracy: ' + str(round(model_history.history['acc'][len(model_history.history['acc'])-1],4))\n","        annotation2 = 'Val accuracy: ' + str(round(model_history.history['val_acc'][len(model_history.history['val_acc'])-1],4))\n","        annotation = annotation1 + ', ' + annotation2\n","        plt.xlabel('epoch \\n' + annotation)\n","        plt.legend(['train','validation'],loc='upper right')\n","        filepath = 'plots/'+ filename + '_accuracy.png'\n","        plt.savefig(filepath,dpi=300, bbox_inches = \"tight\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HLZ0G2dGALit","colab":{}},"source":["def plot_histories(history_list, caption_list, filename,train= False, metric=None):\n","\n","    if train:\n","        title = 'Train'\n","        loss= 'loss'\n","        acc= 'acc'\n","        metric= metric\n","    else:\n","        title = 'Validation'\n","        loss= 'val_loss'\n","        acc= 'val_acc'\n","        metric= 'val_' + metric\n","\n","\n","    loaded_histories=[]\n","    for i in history_list:\n","        history=load_history(i)\n","        loaded_histories += history\n","    \n","    # loss\n","    fig1= plt.figure(1)\n","        \n","    for h in loaded_histories:\n","        plt.plot(h.history[loss])\n","    \n","    plt.title(title+'Loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(caption_list,loc='best')\n","    filepath = 'plots/' + filename + title+'_loss.png'\n","    plt.savefig(filepath, dpi=300,  bbox_inches = \"tight\")\n","      \n","    # accuracy\n","    fig2= plt.figure(2)\n","\n","    for h in loaded_histories:\n","        plt.plot(h.history[acc])\n","\n","    plt.title(title + 'Model Accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(caption_list,loc='best')\n","    filepath = 'plots/'+ filename + title + '_accuracy.png'\n","    plt.savefig(filepath,dpi=300, bbox_inches = \"tight\")\n","\n","    if metric:\n","        fig3= plt.figure(3)\n","\n","        for h in loaded_histories:\n","            plt.plot(h.history[metric])\n","\n","        plt.title(title + 'Model' + metric)\n","        plt.ylabel(metric)\n","        plt.xlabel('epoch')\n","        plt.legend(caption_list,loc='best')\n","        filepath = 'plots/'+ filename + '_' + metric + '.png'\n","        plt.savefig(filepath,dpi=300, bbox_inches = \"tight\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YGMtFy5NuCqA","colab_type":"code","colab":{}},"source":["def reset_weights(model):\n","    \n","    session = K.get_session()\n","    for layer in model.layers: \n","        if hasattr(layer, 'kernel_initializer'):\n","            layer.kernel.initializer.run(session=session)"],"execution_count":0,"outputs":[]}]}